{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import numpy as np\n",
    "import zipfile\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    \"\"\"Load the Jay Chou lyric data set (available in the Chinese book).\"\"\"\n",
    "    with zipfile.ZipFile('../../data/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_indices, char_to_idx, idx_to_char, vocab_size = load_data_jay_lyrics()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 简介\n",
    "\n",
    "它引入了重置门（reset gate）和更新门（update gate）的概念，从而修改了循环神经网络中隐藏状态的计算方式。\n",
    "### 1.重置门和更新门\n",
    "\n",
    "门控循环单元中的重置门和更新门的输入均为当前时间步输入$\\boldsymbol{X}_t$与上一时间步隐藏状态$\\boldsymbol{H}_{t-1}$ ，输出由激活函数为sigmoid函数的全连接层计算得到。\n",
    "\n",
    "具体来说，假设隐藏单元个数为$h$，给定时间步$t$的小批量输入$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$（样本数为$n$，输入个数为$d$）和上一时间步隐藏状态$\\boldsymbol{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$。重置门$\\boldsymbol{R}_t \\in \\mathbb{R}^{n \\times h}$和更新门$\\boldsymbol{Z}_t \\in \\mathbb{R}^{n \\times h}$的计算如下：\n",
    "\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "\\boldsymbol{R}_t = \\sigma(\\boldsymbol{X}_t \\boldsymbol{W}_{xr} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hr} + \\boldsymbol{b}_r),\\\\\n",
    "\\boldsymbol{Z}_t = \\sigma(\\boldsymbol{X}_t \\boldsymbol{W}_{xz} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hz} + \\boldsymbol{b}_z),\n",
    "\\end{aligned}\\end{split}$$\n",
    "\n",
    "其中$\\boldsymbol{W}_{xr}, \\boldsymbol{W}_{xz} \\in \\mathbb{R}^{d \\times h}$和$\\boldsymbol{W}_{hr}, \\boldsymbol{W}_{hz} \\in \\mathbb{R}^{h \\times h}$是权重参数，$\\boldsymbol{b}_r, \\boldsymbol{b}_z \\in \\mathbb{R}^{1 \\times h}$是偏差参数。“多层感知机”一节中介绍过，sigmoid函数可以将元素的值变换到0和1之间。因此，重置门$\\boldsymbol{R}_t$和更新门$\\boldsymbol{Z}_t$中每个元素的值域都是$[0, 1]$。\n",
    "\n",
    "### 2.候选隐藏状态\n",
    "\n",
    "接下来，门控循环单元将计算候选隐藏状态来辅助稍后的隐藏状态计算。我们将当前时间步重置门的输出与上一时间步隐藏状态做按元素乘法（符号为 ⊙ ）。如果重置门中元素值接近0，那么意味着重置对应隐藏状态元素为0，即丢弃上一时间步的隐藏状态。如果元素值接近1，那么表示保留上一时间步的隐藏状态。然后，将按元素乘法的结果与当前时间步的输入连结，再通过含激活函数tanh的全连接层计算出候选隐藏状态，其所有元素的值域为$[-1,1]$。\n",
    "具体来说，时间步$t$的候选隐藏状态$\\tilde{\\boldsymbol{H}}_t \\in \\mathbb{R}^{n \\times h}$的计算为:\n",
    "\n",
    "$$\\tilde{\\boldsymbol{H}}_t = \\text{tanh}(\\boldsymbol{X}_t \\boldsymbol{W}_{xh} + \\left(\\boldsymbol{R}_t \\odot \\boldsymbol{H}_{t-1}\\right) \\boldsymbol{W}_{hh} + \\boldsymbol{b}_h),$$\n",
    "\n",
    "其中$\\boldsymbol{W}_{xh} \\in \\mathbb{R}^{d \\times h}$和$\\boldsymbol{W}_{hh} \\in \\mathbb{R}^{h \\times h}$是权重参数，$\\boldsymbol{b}_h \\in \\mathbb{R}^{1 \\times h}$是偏差参数。从上面这个公式可以看出，重置门控制了上一时间步的隐藏状态如何流入当前时间步的候选隐藏状态。而上一时间步的隐藏状态可能包含了时间序列截至上一时间步的全部历史信息。因此，重置门可以用来丢弃与预测无关的历史信息。\n",
    "\n",
    "### 3.隐藏状态\n",
    "\n",
    "时间步$t$的隐藏状态$\\boldsymbol{H}_t \\in \\mathbb{R}^{n \\times h}$的计算使用当前时间步的更新门$\\boldsymbol{Z}_t$来对上一时间步的隐藏状态$\\boldsymbol{H}_{t-1}$和当前时间步的候选隐藏状态 $\\tilde{\\boldsymbol{H}}_t$做组合：\n",
    "\n",
    "$$\\boldsymbol{H}_t = \\boldsymbol{Z}_t \\odot \\boldsymbol{H}_{t-1}  + (1 - \\boldsymbol{Z}_t) \\odot \\tilde{\\boldsymbol{H}}_t.$$\n",
    "\n",
    "### 4.输出\n",
    "\n",
    "$$\\boldsymbol{O}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q.$$\n",
    "\n",
    "\n",
    "![image](http://zh.d2l.ai/_images/gru_3.svg)\n",
    "\n",
    "\n",
    "我们对门控循环单元的设计稍作总结：\n",
    "\n",
    "#### 重置门有助于捕捉时间序列里短期的依赖关系；\n",
    "#### 更新门有助于捕捉时间序列里长期的依赖关系。\n",
    "\n",
    "\n",
    "## 从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 初始化模型参数，num_hidden为隐藏层个数\n",
    "def gru(inputs,states,params):\n",
    "    w_xr,w_hr,b_r,w_xz,w_hz,b_z,w_xh,w_hh,b_h,w_hq,b_q = params\n",
    "    H = states,\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        r = keras.activations.sigmoid(tf.matmul(x,w_xr) + tf.matmul(H,w_hr) + b_r)\n",
    "        z = keras.activations.sigmoid(tf.matmul(x,w_xz) + tf.matmul(H,w_hz) + b_z)\n",
    "        h_hat = keras.activations.tanh(tf.matmul(x,w_xh) + tf.matmul(tf.multiply(H,r),w_hh) + b_h)\n",
    "        H = tf.multiply(z,H) + tf.multiply((1 - z),h_hat)\n",
    "        y = keras.activations.softmax(tf.matmul(H,w_hq)+b_q)\n",
    "        outputs.append(y)\n",
    "    return tf.squeeze(tf.stack(outputs)),tf.squeeze(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    def _three():\n",
    "        return tf.random.normal(shape=(num_inputs,num_hiddens)),tf.random.normal(shape=(num_hiddens,num_hiddens)),tf.zeros(shape=(1,num_hiddens))\n",
    "    \n",
    "    w_xr,w_hr,b_r = _three()\n",
    "    w_xz,w_hz,b_z = _three()\n",
    "    w_xh,w_hh,b_h = _three()\n",
    "    \n",
    "    w_hq = tf.random.normal(shape=(num_hiddens,num_outputs))\n",
    "    b_q = tf.zeros(shape=(1,num_outputs))\n",
    "    \n",
    "    return w_xr,w_hr,b_r,w_xz,w_hz,b_z,w_xh,w_hh,b_h,w_hq,b_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_gru_state(batch_size, num_hiddens):\n",
    "    return tf.zeros(shape=(batch_size, num_hiddens)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(X,depth):\n",
    "    outs = [tf.one_hot(x,depth=depth) for x in tf.transpose(X)]\n",
    "    return tf.stack(outs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(10)).reshape((2,5))\n",
    "inputs = to_onehot(x,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=276, shape=(5, 2, 1027), dtype=float32, numpy=\n",
       " array([[[1.8270682e-11, 2.5593363e-05, 6.3220362e-08, ...,\n",
       "          3.9930143e-07, 1.4222721e-02, 3.2587191e-06],\n",
       "         [4.7124170e-13, 8.5673486e-09, 8.2448855e-07, ...,\n",
       "          9.7057195e-03, 7.7105735e-09, 1.6129597e-09]],\n",
       " \n",
       "        [[1.7154330e-18, 1.2036309e-15, 1.4542325e-13, ...,\n",
       "          1.4132907e-18, 1.0188059e-03, 4.0110215e-18],\n",
       "         [1.4956226e-21, 3.1594125e-16, 6.2469773e-15, ...,\n",
       "          7.0781132e-09, 2.9770661e-15, 5.6619004e-17]],\n",
       " \n",
       "        [[6.3793612e-18, 9.3383079e-12, 1.6710391e-14, ...,\n",
       "          1.7759067e-14, 8.0174162e-14, 6.6339607e-20],\n",
       "         [1.4138936e-19, 7.5977135e-18, 3.5574745e-25, ...,\n",
       "          5.4918436e-22, 3.0829259e-11, 1.2664023e-13]],\n",
       " \n",
       "        [[1.0444699e-08, 1.4076769e-12, 3.1676660e-12, ...,\n",
       "          3.1688436e-20, 5.2080968e-15, 8.8241148e-10],\n",
       "         [4.8150122e-07, 2.3504249e-15, 3.6923222e-24, ...,\n",
       "          1.3702804e-14, 7.0515479e-13, 1.0034578e-18]],\n",
       " \n",
       "        [[8.9887599e-06, 4.5574835e-16, 4.3891272e-17, ...,\n",
       "          1.1168479e-21, 1.8335121e-15, 1.4625329e-09],\n",
       "         [4.1846432e-10, 5.8810701e-24, 5.8293763e-27, ...,\n",
       "          1.8204759e-22, 4.2895099e-15, 2.2796884e-23]]], dtype=float32)>,\n",
       " <tf.Tensor: id=277, shape=(2, 256), dtype=float32, numpy=\n",
       " array([[ 0.99996936,  0.99920344,  0.9998857 ,  0.9995872 , -0.8047667 ,\n",
       "         -0.9990568 , -0.7770012 , -0.99999833, -0.93511504, -0.2953924 ,\n",
       "         -0.9998462 ,  0.99639016, -0.99970675,  0.99273753,  0.9999382 ,\n",
       "          0.9995447 ,  0.9824946 ,  0.6602561 , -0.98021126,  0.21869117,\n",
       "          0.999665  , -0.17984642, -0.7339814 ,  0.98667204, -1.        ,\n",
       "         -0.99354094,  0.9856059 ,  0.9999985 ,  0.3164123 ,  0.9995354 ,\n",
       "         -0.29958203, -0.9994946 ,  0.99938023, -0.999791  ,  0.5587983 ,\n",
       "         -0.35395598, -0.46071327, -0.52479476, -0.381977  , -0.98984146,\n",
       "          0.883715  ,  0.9998808 , -0.4767528 ,  0.4049888 , -0.9999649 ,\n",
       "          0.98362315,  0.92288613, -0.95881426,  0.8759431 , -0.21450043,\n",
       "         -0.10189656, -0.9999945 ,  0.43409067, -0.7044762 , -0.99946815,\n",
       "         -0.99463713,  0.87836206, -0.28042668,  0.47292644,  0.43039098,\n",
       "          0.18605615,  0.30379274,  0.99926364, -1.        , -0.39833832,\n",
       "         -0.9533918 ,  0.26790816,  0.9999869 ,  0.9999813 ,  0.71193874,\n",
       "         -0.702226  , -0.9895359 , -0.99999976, -0.9999997 , -0.9978566 ,\n",
       "          0.94550854, -1.        , -0.3252618 ,  0.48859945,  0.9877898 ,\n",
       "          0.9990463 , -0.0911251 , -0.0549828 ,  0.9922179 ,  0.99848175,\n",
       "         -0.99952805, -0.9996644 , -0.2543445 , -1.        ,  0.78730917,\n",
       "         -0.28443122, -0.7366833 , -0.9991844 , -0.99991226, -0.9816997 ,\n",
       "         -0.9463864 ,  0.48749077, -0.07076547, -0.9812955 , -0.9964732 ,\n",
       "         -0.9964605 ,  0.9999998 ,  0.82161677, -0.0883719 , -0.7732415 ,\n",
       "          0.8418562 ,  0.74497515, -0.76221377, -0.9717514 , -0.9621279 ,\n",
       "          0.9999855 ,  0.78574204,  0.6355425 ,  0.9999882 ,  0.93377066,\n",
       "         -0.9676186 ,  0.61996776,  0.04711531,  0.9999998 ,  0.99766296,\n",
       "         -0.99211484, -0.9967749 , -0.9966081 , -0.20513487, -0.9880184 ,\n",
       "          0.9955281 ,  0.99253076,  0.20167975, -0.9999982 ,  0.5866006 ,\n",
       "         -0.7335473 ,  0.99999756, -0.9953761 , -0.9999935 , -0.42851657,\n",
       "         -1.        , -1.        ,  0.4952659 ,  0.999973  ,  0.99975777,\n",
       "          0.9995281 ,  0.966947  ,  0.99419236,  0.97754693, -0.6518832 ,\n",
       "         -0.23528153,  0.99982417,  1.        , -0.999982  ,  0.9999555 ,\n",
       "         -0.29500324, -0.96515465, -0.34677216,  0.2692915 ,  0.00693483,\n",
       "          1.        ,  0.9605938 , -0.00235322, -0.9878817 , -0.18932767,\n",
       "          0.78262895,  0.7816767 ,  0.9668177 ,  0.88742334,  0.9410145 ,\n",
       "          0.91923714, -0.9998614 , -0.61520505, -0.99578553, -0.99999374,\n",
       "         -0.99972147,  0.99789864,  0.9999994 ,  0.9999995 , -0.3114774 ,\n",
       "         -0.3781749 ,  0.64077854, -0.9614469 ,  0.99991196,  0.7824079 ,\n",
       "          0.9999938 ,  0.9999934 ,  0.09591956, -0.99999994,  1.        ,\n",
       "          0.9258232 ,  0.23445237,  0.972134  , -0.9995279 ,  0.7318311 ,\n",
       "         -0.9994402 ,  0.99999976, -0.9980839 ,  0.9994826 ,  0.3918558 ,\n",
       "          0.9053756 ,  0.3643858 , -0.7536026 ,  0.73785836,  0.92310494,\n",
       "         -0.9998884 ,  0.6729691 ,  0.999996  ,  0.9427737 ,  0.99003184,\n",
       "          0.57752216, -0.83523107,  0.8413482 ,  0.9994938 , -0.99880296,\n",
       "         -0.76509666,  0.7505872 , -0.03827998,  0.6960755 ,  0.99880123,\n",
       "         -0.1319873 , -0.6352109 ,  0.7045092 , -0.74317193, -0.93664193,\n",
       "         -0.6831111 , -0.16060813,  0.98770446,  0.47898996,  1.        ,\n",
       "          0.17689171, -1.        ,  0.9650383 , -0.99999785, -0.07160768,\n",
       "          0.79586846,  0.769697  , -0.29003173,  0.603434  ,  0.9999919 ,\n",
       "          0.42035988, -0.9977261 ,  0.99997425,  0.9998276 , -0.19799809,\n",
       "         -0.9964744 , -0.7823306 ,  0.9897218 , -0.9952609 , -0.2108332 ,\n",
       "         -0.9989958 ,  0.38330415, -0.9998082 , -0.20727465,  0.9661425 ,\n",
       "          0.83977485,  0.39517555, -0.05439087,  0.18451074, -0.9981672 ,\n",
       "          0.9999996 ],\n",
       "        [-0.31393707,  1.        , -0.9986355 , -0.9838473 ,  0.9656696 ,\n",
       "          0.9769313 ,  1.        ,  0.9876895 , -0.965765  ,  0.85390365,\n",
       "         -1.        , -0.99999624,  0.9999995 , -0.9886473 , -0.9637108 ,\n",
       "          0.9999819 ,  0.9859125 ,  0.9999999 , -0.73402244,  0.99095213,\n",
       "          0.99922055,  0.9999984 , -0.8835337 ,  0.9849752 , -0.9985787 ,\n",
       "         -0.01628959,  0.9995873 , -0.84124327,  0.7872144 , -0.870456  ,\n",
       "          0.35045052,  0.9921299 ,  0.78688484,  0.4121695 , -1.        ,\n",
       "          0.99999875, -0.99993175, -1.        ,  0.36901763,  0.9999911 ,\n",
       "         -0.05931916, -0.99794495, -0.18937632, -0.96069443,  0.16710496,\n",
       "          0.42411134, -0.78991365, -0.28400174,  0.99184537, -0.99980396,\n",
       "          0.99962574, -0.99999994,  0.9999975 , -0.9963466 , -0.04085942,\n",
       "          0.97061   ,  0.9999949 ,  0.8314523 ,  0.9273828 , -0.9999968 ,\n",
       "         -0.98809624, -0.45673546, -0.9562829 , -0.2787193 , -0.9735718 ,\n",
       "         -0.9925685 , -0.99882025, -0.9999911 ,  0.41596457,  0.4571874 ,\n",
       "          0.9782281 , -0.9711536 ,  0.3934655 , -0.77145034,  0.99999875,\n",
       "          0.14896607,  0.9841267 ,  0.8800046 ,  0.08991335,  0.9997983 ,\n",
       "          1.        , -0.818257  , -0.13320696,  0.8127157 , -0.9999041 ,\n",
       "         -0.94238836,  0.22646819, -0.9708433 ,  0.7889127 ,  0.9568009 ,\n",
       "          0.999995  ,  0.7009935 ,  0.6445467 ,  0.8222602 , -0.9730029 ,\n",
       "          0.9992528 ,  1.        ,  0.99881804,  0.99960965, -1.        ,\n",
       "         -0.9713066 , -0.9206017 ,  0.9766437 ,  0.9999995 , -0.7498715 ,\n",
       "          0.7067189 , -0.99999696, -0.0129731 ,  0.9999997 ,  0.99999464,\n",
       "          0.8639989 ,  0.17403731, -0.07485012,  0.96363586, -0.48351502,\n",
       "          0.6299199 ,  0.9999521 ,  0.8677218 , -0.99962276,  0.5957102 ,\n",
       "          0.978902  , -0.5167102 , -0.99999994,  0.15215659, -0.9954004 ,\n",
       "          1.        ,  0.99739224,  0.16986723, -0.99978185, -0.99999785,\n",
       "          0.9999541 , -1.        ,  0.99994165, -0.19644612, -0.59940946,\n",
       "         -1.        , -0.99393564,  1.        ,  0.99999946, -0.08520587,\n",
       "          0.58067167, -0.99566495, -0.9835429 , -0.08826704, -0.9978844 ,\n",
       "          0.4450456 , -0.47720438,  1.        ,  0.99999964, -0.26303115,\n",
       "         -0.223425  ,  0.06679526,  0.99999774,  0.69667614,  0.23945057,\n",
       "          0.739385  , -0.9224244 ,  0.57831055,  0.99983805, -0.9894063 ,\n",
       "          0.95987195,  0.99998796, -0.9948765 , -0.68937   ,  0.9633118 ,\n",
       "         -0.71931255, -0.8537159 ,  0.75614023, -0.31582242, -0.8935196 ,\n",
       "         -0.9999679 ,  0.62879455,  0.9998458 , -0.4243655 ,  0.65248185,\n",
       "         -0.7430429 , -0.9999488 ,  0.93939614,  1.        ,  0.99991906,\n",
       "          0.95389956,  0.9874752 , -0.13050446, -1.        , -0.9999907 ,\n",
       "          0.98186797,  0.69928783,  0.9726752 , -0.30509716, -1.        ,\n",
       "          0.1851658 ,  0.09214402, -0.44697702, -0.04681181,  0.9811826 ,\n",
       "         -0.87537414,  0.7309434 ,  0.99138546,  0.15677251,  0.99999994,\n",
       "         -1.        , -0.99357474,  0.08023711,  0.9999734 , -0.08987525,\n",
       "          0.98784363,  0.3764628 ,  0.9558074 ,  0.99999994,  0.6984139 ,\n",
       "         -0.95485795,  0.9998574 ,  0.9637852 ,  0.9634778 , -0.74795216,\n",
       "         -0.5166263 , -0.8716393 ,  0.66297156,  0.21537663,  0.9999406 ,\n",
       "          0.9994073 ,  0.58464867, -0.27126372,  0.80965686, -0.99999917,\n",
       "         -0.9551661 ,  0.05163263,  0.9999467 ,  0.32078585,  0.99999905,\n",
       "          0.99999577, -0.8784972 ,  0.5578928 , -0.99414474, -0.68009573,\n",
       "         -0.622414  , -0.35550803,  0.87744737, -0.9989842 , -0.71810156,\n",
       "          0.8290403 ,  0.9993822 ,  0.7101717 ,  0.7825013 ,  0.9998863 ,\n",
       "          0.99999434,  0.30287424, -0.42931375,  0.9998459 , -0.93678445,\n",
       "          0.99999785,  0.9600356 ,  0.95220876,  0.96738625, -0.97870266,\n",
       "         -1.        ]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = init_gru_state(x.shape[0],num_hiddens)\n",
    "gru(inputs,state,init_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow 中的GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "def load_data_jay_lyrics():\n",
    "    \"\"\"Load the Jay Chou lyric data set (available in the Chinese book).\"\"\"\n",
    "    with zipfile.ZipFile('../../data/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n', '').replace('\\r', '')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    jieba_cut = jieba.cut(corpus_chars)\n",
    "    chars = []\n",
    "    for char in jieba_cut:\n",
    "        chars.append(char)\n",
    "    idx_to_char = list(set(chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_indices, char_to_idx, idx_to_char, vocab_size = load_data_jay_lyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6379, 1258, 1258, 1258)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_indices),len( char_to_idx),len( idx_to_char), vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练数据\n",
    "seq_lenght = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0,vocab_size-seq_lenght,1):\n",
    "    seq_in = corpus_indices[i:i+seq_lenght+1]\n",
    "    dataX.append(seq_in)\n",
    "\n",
    "np.random.shuffle(dataX)\n",
    "for i in range(len(dataX)):\n",
    "    dataY.append([dataX[i][seq_lenght]])\n",
    "    dataX[i] = dataX[i][:seq_lenght]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1158, 1158)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataX),len(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建模型\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(vocab_size,64,input_length=seq_lenght),\n",
    "    layers.GRU(64,activation=\"softmax\",return_sequences=True),\n",
    "    layers.GRU(32,activation=\"softmax\",return_sequences=True),\n",
    "    layers.GRU(16,activation=\"softmax\"),\n",
    "    layers.Dense(vocab_size,activation=\"softmax\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy, optimizer=adam,metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 100, 64)           80512     \n",
      "_________________________________________________________________\n",
      "gru_10 (GRU)                 (None, 100, 64)           24960     \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 100, 32)           9408      \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 16)                2400      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1258)              21386     \n",
      "=================================================================\n",
      "Total params: 138,666\n",
      "Trainable params: 138,666\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1158 samples\n",
      "Epoch 1/5\n",
      "1158/1158 [==============================] - 3s 3ms/sample - loss: 4.6386 - acc: 0.1028\n",
      "Epoch 2/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 4.6080 - acc: 0.0993\n",
      "Epoch 3/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 4.5753 - acc: 0.1028\n",
      "Epoch 4/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 4.5440 - acc: 0.1002\n",
      "Epoch 5/5\n",
      "1158/1158 [==============================] - 3s 2ms/sample - loss: 4.5109 - acc: 0.1010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20febbad470>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataX,dataY,batch_size=32,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed : \n",
      " 配上几斤的牛肉我说店小二 三两银够不够景色入秋 漫天黄沙凉过塞北的客栈人多 牧草有没有 我马儿有些瘦天涯尽头 满脸风霜落寞 近乡情怯的我相思寄红豆 相思寄红豆无能为力的在人海中漂泊心伤透娘子她人在江南等我 泪不休 语沉默娘子她人在江南等我 泪不休 语沉默一壶好酒 再来一碗热粥 配上几斤的牛肉我说店小二 三两\n",
      "开始生成，生成长度为 100\n",
      "的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的的"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed : \")\n",
    "print(''.join([idx_to_char[value] for value in pattern]))\n",
    "n_generation = 100  # 生成的长度\n",
    "print('开始生成，生成长度为', n_generation)\n",
    "finall_result = []\n",
    "for i in range(n_generation):\n",
    "    x = np.reshape(pattern, (1, len(pattern)))\n",
    "    prediction = model.predict(x, verbose=0)[0]\n",
    "    index = np.argmax(prediction)\n",
    "    result = idx_to_char[index]\n",
    "    # sys.stdout.write(result)\n",
    "    finall_result.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "\n",
    "for i in range(len(finall_result)):\n",
    "    if finall_result[i] != '。':\n",
    "        print(finall_result[i], end='')\n",
    "    else:\n",
    "        print('。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "看远方的星是否听的见手牵手一步两步三步四步望著天 看星星一颗两颗三颗四颗 连成线背著背默默许下心愿看远方的星如果听的见它一定实现它一定实现娘子 娘子却依旧每日 折一枝杨柳你在那里 在小村外的溪边河口默默等著我娘子依旧每日折一枝杨柳你在那里 在小村外的溪边 默默等待 娘子一壶好酒 再来一碗热粥 配上几斤的\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(dataX) - 1)\n",
    "pattern = dataX[start]\n",
    "print(''.join([idx_to_char[value] for value in pattern]))\n",
    "n_generation = 100  # 生成的长度\n",
    "x = np.reshape(pattern, (1, len(pattern)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=67325, shape=(1, 1258), dtype=float32, numpy=\n",
       "array([[1.5346650e-03, 1.7639837e-05, 1.6419698e-03, ..., 1.7816583e-05,\n",
       "        1.8238619e-05, 1.6785410e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(tf.squeeze(model(x))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=98441, shape=(), dtype=float32, numpy=0.051233962>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(model(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'的'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_char[966]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
