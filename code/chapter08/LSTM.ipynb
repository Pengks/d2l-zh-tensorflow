{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import zipfile\n",
    "import numpy as np\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1027"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_jay_lyrics():\n",
    "    \"\"\"Load the Jay Chou lyric data set (available in the Chinese book).\"\"\"\n",
    "    with zipfile.ZipFile('../../data/jaychou_lyrics.txt.zip') as zin:\n",
    "        with zin.open('jaychou_lyrics.txt') as f:\n",
    "            corpus_chars = f.read().decode('utf-8')\n",
    "    corpus_chars = corpus_chars.replace('\\n', ' ').replace('\\r', ' ')\n",
    "    corpus_chars = corpus_chars[0:10000]\n",
    "    idx_to_char = list(set(corpus_chars))\n",
    "    char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
    "    vocab_size = len(char_to_idx)\n",
    "    corpus_indices = [char_to_idx[char] for char in corpus_chars]\n",
    "    return corpus_indices, char_to_idx, idx_to_char, vocab_size\n",
    "\n",
    "corpus_indices, char_to_idx, idx_to_char, vocab_size = load_data_jay_lyrics()\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算法\n",
    "\n",
    "LSTM 中引入了3个门，即输入门（input gate）、遗忘门（forget gate）和输出门（output gate），以及与隐藏状态形状相同的记忆细胞（某些文献把记忆细胞当成一种特殊的隐藏状态），从而记录额外的信息。\n",
    "\n",
    "### 1. 输入门、遗忘门和输出门\n",
    "\n",
    "与门控循环单元中的重置门和更新门一样,长短期记忆的门的输入均为当前时间步输入$\\boldsymbol{X}_t$与上一时间步隐藏状态$\\boldsymbol{H}_{t-1}$，输出由激活函数为sigmoid函数的全连接层计算得到。这3个门元素的值域均为 $[0,1]$ 。\n",
    "\n",
    "具体来说，假设隐藏单元个数为$h$，给定时间步$t$的小批量输入$\\boldsymbol{X}_t \\in \\mathbb{R}^{n \\times d}$（样本数为$n$，输入个数为$d$）和上一时间步隐藏状态$\\boldsymbol{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$。 时间步$t$的输入门$\\boldsymbol{I}_t \\in \\mathbb{R}^{n \\times h}$、遗忘门$\\boldsymbol{F}_t \\in \\mathbb{R}^{n \\times h}$和输出门$\\boldsymbol{O}_t \\in \\mathbb{R}^{n \\times h}$分别计算如下：\n",
    "\n",
    "$$\\begin{split}\\begin{aligned}\n",
    "\\boldsymbol{I}_t &= \\sigma(\\boldsymbol{X}_t \\boldsymbol{W}_{xi} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hi} + \\boldsymbol{b}_i),\\\\\n",
    "\\boldsymbol{F}_t &= \\sigma(\\boldsymbol{X}_t \\boldsymbol{W}_{xf} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hf} + \\boldsymbol{b}_f),\\\\\n",
    "\\boldsymbol{O}_t &= \\sigma(\\boldsymbol{X}_t \\boldsymbol{W}_{xo} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{ho} + \\boldsymbol{b}_o),\n",
    "\\end{aligned}\\end{split}$$\n",
    "\n",
    "其中的$\\boldsymbol{W}_{xi}, \\boldsymbol{W}_{xf}, \\boldsymbol{W}_{xo} \\in \\mathbb{R}^{d \\times h}$和$\\boldsymbol{W}_{hi}, \\boldsymbol{W}_{hf}, \\boldsymbol{W}_{ho} \\in \\mathbb{R}^{h \\times h}$是权重参数，$\\boldsymbol{b}_i, \\boldsymbol{b}_f, \\boldsymbol{b}_o \\in \\mathbb{R}^{1 \\times h}$是偏差参数。\n",
    "\n",
    "### 2.候选记忆细胞\n",
    "\n",
    "长短期记忆需要计算候选记忆细胞$\\tilde{\\boldsymbol{C}}_t$。它的计算与上面介绍的3个门类似，但使用了值域在$[−1,1]$的tanh函数作为激活函数\n",
    "\n",
    "具体来说，时间步$t$的候选记忆细胞$\\tilde{\\boldsymbol{C}}_t \\in \\mathbb{R}^{n \\times h}$的计算为\n",
    "$$\\tilde{\\boldsymbol{C}}_t = \\text{tanh}(\\boldsymbol{X}_t \\boldsymbol{W}_{xc} + \\boldsymbol{H}_{t-1} \\boldsymbol{W}_{hc} + \\boldsymbol{b}_c),$$\n",
    "\n",
    "其中$\\boldsymbol{W}_{xc} \\in \\mathbb{R}^{d \\times h}$和$\\boldsymbol{W}_{hc} \\in \\mathbb{R}^{h \\times h}$是权重参数，$\\boldsymbol{b}_c \\in \\mathbb{R}^{1 \\times h}$是偏差参数。\n",
    "\n",
    "### 3.记忆细胞\n",
    "\n",
    "我们可以通过元素值域在$[0,1]$的输入门、遗忘门和输出门来控制隐藏状态中信息的流动，这一般也是通过使用按元素乘法（符号为 ⊙ ）来实现的。当前时间步记忆细胞$\\boldsymbol{C}_t \\in \\mathbb{R}^{n \\times h}$的计算组合了上一时间步记忆细胞和当前时间步候选记忆细胞的信息，并通过遗忘门和输入门来控制信息的流动：\n",
    "$$\\boldsymbol{C}_t = \\boldsymbol{F}_t \\odot \\boldsymbol{C}_{t-1} + \\boldsymbol{I}_t \\odot \\tilde{\\boldsymbol{C}}_t.$$\n",
    "\n",
    "### 4.隐藏状态\n",
    "有了记忆细胞以后，接下来我们还可以通过输出门来控制从记忆细胞到隐藏状态$\\boldsymbol{H}_t \\in \\mathbb{R}^{n \\times h}$的信息的流动：\n",
    "$$\\boldsymbol{H}_t = \\boldsymbol{O}_t \\odot \\text{tanh}(\\boldsymbol{C}_t).$$\n",
    "这里的tanh函数确保隐藏状态元素值在-1到1之间。需要注意的是，当输出门近似1时，记忆细胞信息将传递到隐藏状态供输出层使用；当输出门近似0时，记忆细胞信息只自己保留。下图展示了长短期记忆中隐藏状态的计算。\n",
    "\n",
    "![image](http://zh.d2l.ai/_images/lstm_3.svg)\n",
    "\n",
    "### 5.最终输出\n",
    "\n",
    "$$\\boldsymbol{Y}_t = \\boldsymbol{H}_t \\boldsymbol{W}_{hq} + \\boldsymbol{b}_q.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_hiddens, num_outputs = vocab_size, 256, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(inputs,states,params):\n",
    "    w_xi,w_hi,b_i,w_xf,w_hf,b_f,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_hq,b_q = params\n",
    "    H,C = states\n",
    "    outputs = []\n",
    "    for x in inputs:\n",
    "        #忘记门\n",
    "        f = keras.activations.sigmoid(tf.matmul(x,w_xf) + tf.matmul(H,w_hf) + b_f)\n",
    "        # 输入门\n",
    "        i = keras.activations.sigmoid(tf.matmul(x,w_xi) + tf.matmul(H,w_hi) + b_i)\n",
    "        # 输出门\n",
    "        o = keras.activations.sigmoid(tf.matmul(x,w_xo) + tf.matmul(H,w_ho) + b_o)\n",
    "        # 候选记忆细胞\n",
    "        c_hat = keras.activations.tanh(tf.matmul(x,w_xc) + tf.matmul(H,w_hc) + b_c)\n",
    "        # 记忆细胞\n",
    "        C = tf.multiply(f,C) + tf.multiply(i,c_hat)\n",
    "        # 隐藏层\n",
    "        H = tf.multiply(o,keras.activations.tanh(C))\n",
    "        y = tf.matmul(H,w_hq) + b_q\n",
    "        outputs.append(y)\n",
    "    return tf.stack(outputs),(H,C)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lstm_states(batch_size,num_hiddens):\n",
    "    return (\n",
    "        tf.zeros(shape=(batch_size,num_hiddens)),\n",
    "        tf.zeros(shape=(batch_size,num_hiddens))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    \n",
    "    def _threes():\n",
    "        return (tf.random.normal(shape=(num_inputs,num_hiddens)),tf.random.normal(shape=(num_hiddens,num_hiddens)),tf.zeros(shape=(1,num_hiddens)))\n",
    "    \n",
    "    w_xi,w_hi,b_i = _threes()\n",
    "    w_xf,w_hf,b_f = _threes()\n",
    "    w_xo,w_ho,b_o = _threes()\n",
    "    w_xc,w_hc,b_c = _threes()\n",
    "    w_hq,b_q = tf.random.normal(shape=(num_hiddens,num_outputs)),tf.zeros(shape=(1,num_outputs))\n",
    "    \n",
    "    return w_xi,w_hi,b_i,w_xf,w_hf,b_f,w_xo,w_ho,b_o,w_xc,w_hc,b_c,w_hq,b_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(X,depth):\n",
    "    outs = [tf.one_hot(x,depth=depth) for x in tf.transpose(X)]\n",
    "    return tf.stack(outs,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(5)).reshape((1,5))\n",
    "inputs = to_onehot(x,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=1294, shape=(5, 1, 1027), dtype=float32, numpy=\n",
       " array([[[  0.07173868,   1.6845028 ,   5.2634587 , ...,  -0.09351012,\n",
       "            2.270501  ,   1.3396002 ]],\n",
       " \n",
       "        [[  7.1314826 ,  -0.95359766,   5.609708  , ...,  -7.7840066 ,\n",
       "           10.76433   ,   0.508923  ]],\n",
       " \n",
       "        [[  1.6182783 ,  -1.1211449 ,  12.420524  , ...,  -7.902752  ,\n",
       "            7.1471243 ,  -7.1611023 ]],\n",
       " \n",
       "        [[  7.848685  ,   0.68195987,   5.4883237 , ...,   3.5423014 ,\n",
       "           -2.8229854 , -12.434613  ]],\n",
       " \n",
       "        [[ -4.4162593 ,   9.665938  ,   7.026255  , ...,  13.074351  ,\n",
       "           -2.5717328 ,   0.456568  ]]], dtype=float32)>,\n",
       " (<tf.Tensor: id=1291, shape=(1, 256), dtype=float32, numpy=\n",
       "  array([[-4.52327952e-02, -6.80377185e-01, -1.22630297e-06,\n",
       "          -8.65447223e-01,  2.64880329e-01,  1.59439128e-02,\n",
       "          -9.01117772e-02, -1.64594792e-03, -7.25754499e-01,\n",
       "          -8.60191360e-02,  3.62363756e-01,  7.82752689e-03,\n",
       "           2.13399503e-08,  2.97417641e-01,  6.57713099e-06,\n",
       "           1.96251995e-03,  6.73672497e-01, -8.25473249e-01,\n",
       "          -6.70723637e-08, -5.54692410e-02, -4.23514396e-02,\n",
       "           3.87937650e-02, -9.50184464e-02,  2.76970327e-01,\n",
       "           1.77223166e-03,  6.64154947e-01,  4.03038925e-03,\n",
       "          -7.06054436e-07, -1.30778408e-05, -1.64205011e-03,\n",
       "           3.56282033e-02,  1.99337136e-02, -6.76888012e-05,\n",
       "           3.63655738e-03,  6.36149228e-01, -7.32113361e-01,\n",
       "          -4.54633325e-01,  3.81287723e-03, -1.29856856e-03,\n",
       "          -2.16867492e-01,  2.48667654e-02,  2.40966347e-05,\n",
       "           8.84918869e-01, -6.55476272e-01,  3.38270575e-01,\n",
       "          -3.27387780e-01,  9.84938975e-09,  4.81830025e-03,\n",
       "          -7.70973135e-03,  6.03037979e-03, -1.94105247e-04,\n",
       "          -4.38749999e-01,  4.50621098e-02,  5.97953971e-04,\n",
       "          -1.13390513e-06, -1.82089917e-02,  1.12159988e-02,\n",
       "           8.57527077e-01,  3.10821837e-04,  9.24610067e-03,\n",
       "           2.98031811e-02, -8.51005432e-04, -5.82117168e-03,\n",
       "           2.15403184e-01,  7.70773172e-01,  2.87368577e-02,\n",
       "           1.66581914e-01,  3.68416688e-04,  2.70849298e-04,\n",
       "          -1.53021247e-03,  1.32102236e-01,  1.92671716e-01,\n",
       "          -6.70799494e-01,  9.03914273e-01,  2.04579145e-01,\n",
       "           8.02833089e-09,  5.31630963e-02,  1.36555347e-04,\n",
       "           1.64289195e-02,  8.82918060e-01,  4.24823258e-03,\n",
       "          -7.48113573e-01,  4.46137816e-01,  4.51781958e-01,\n",
       "          -2.85641372e-01,  9.81568126e-04, -1.03884581e-02,\n",
       "           1.53833884e-03, -7.53524303e-01,  1.16741294e-02,\n",
       "           4.70492921e-07, -5.64762950e-02,  9.11280047e-04,\n",
       "           1.05345296e-03,  2.87778318e-01, -1.51235327e-01,\n",
       "          -5.92356455e-03, -3.09981971e-07, -4.42281540e-04,\n",
       "           3.56129855e-01,  5.13734156e-03, -1.09203284e-05,\n",
       "           5.79339743e-01,  2.02015392e-03,  4.65131402e-01,\n",
       "          -2.24614576e-01,  4.88959020e-03,  4.02748583e-06,\n",
       "           3.78765106e-01, -6.85483396e-01,  3.90151073e-03,\n",
       "           4.29015815e-01,  3.19412686e-02, -7.57193029e-01,\n",
       "           1.76834772e-04,  5.70373118e-01, -9.78872023e-08,\n",
       "           7.95959868e-03, -6.95980370e-01,  1.30886182e-01,\n",
       "           9.45819989e-02,  6.90087618e-05, -7.80252140e-06,\n",
       "           7.16607901e-04, -4.77571692e-03, -4.58012968e-01,\n",
       "          -1.66352406e-01, -3.32017010e-03,  5.45355342e-02,\n",
       "           1.74750462e-01,  4.01934654e-01, -5.20929694e-01,\n",
       "           2.44037099e-02,  6.39448464e-01,  7.12967245e-03,\n",
       "           1.33837927e-02,  7.03377008e-01,  2.14102313e-01,\n",
       "          -1.37938870e-04,  5.95879834e-03,  3.49638563e-09,\n",
       "          -1.14466295e-01,  1.94965228e-02,  1.31622225e-01,\n",
       "          -2.67472501e-07,  9.31322793e-05,  6.85227462e-07,\n",
       "           9.43966135e-02,  7.37731040e-01, -3.04180607e-02,\n",
       "           4.06777933e-02,  7.25864172e-01, -2.15974748e-01,\n",
       "           2.90842596e-02,  1.94328912e-02,  6.26501516e-02,\n",
       "          -2.17530085e-03, -7.09772527e-01, -3.96825817e-05,\n",
       "           7.12922439e-02, -4.06270698e-02, -1.01796424e-04,\n",
       "           1.64811954e-01, -6.11844122e-01, -8.18458915e-01,\n",
       "           1.32579298e-04,  4.94927883e-01,  4.92761319e-05,\n",
       "           2.19432488e-02, -1.68140307e-02, -1.20202161e-03,\n",
       "           1.27646923e-01,  9.08150971e-01,  2.53742814e-01,\n",
       "          -8.78219396e-07,  4.84197259e-01, -7.87869841e-02,\n",
       "          -6.48094565e-02,  9.29779410e-01,  5.32325637e-03,\n",
       "           6.77446878e-05, -1.90148203e-04, -1.14920782e-02,\n",
       "           6.17398357e-04,  5.01093149e-01,  4.57195853e-07,\n",
       "           4.93904084e-01, -3.12065840e-01,  9.37057720e-09,\n",
       "           9.90450010e-02, -7.73206353e-01,  5.92289900e-04,\n",
       "          -8.49361913e-06,  9.66707766e-02,  5.51045060e-01,\n",
       "          -7.13499665e-01, -7.88496077e-01,  4.94097024e-01,\n",
       "           8.19009602e-01,  2.18268722e-01, -3.68500804e-03,\n",
       "           1.18293799e-01, -7.59068012e-01, -6.58106208e-02,\n",
       "          -5.26284218e-01,  4.57784534e-01,  4.77032678e-04,\n",
       "          -2.71476321e-02, -3.21412153e-05, -1.63156167e-02,\n",
       "          -1.81034710e-02, -6.43348575e-01, -1.24435492e-01,\n",
       "           1.26835600e-01,  7.61393785e-01, -2.02675819e-01,\n",
       "          -4.45041806e-05,  4.04167593e-01,  7.02593148e-01,\n",
       "           5.07439068e-03, -4.01699305e-01,  5.78280330e-01,\n",
       "          -5.83287895e-01,  9.21985030e-01,  3.85950261e-05,\n",
       "           2.54034996e-01,  4.95727360e-01,  1.76492293e-04,\n",
       "           5.15622914e-01,  3.85067686e-02,  6.08831346e-01,\n",
       "           6.95713460e-01,  6.05520248e-01, -5.28653637e-02,\n",
       "          -6.96424171e-02, -7.58391500e-01, -3.64054198e-04,\n",
       "          -3.49336624e-01,  7.97806025e-01, -1.23027792e-06,\n",
       "           4.88315254e-01,  1.77314524e-02,  1.01652667e-02,\n",
       "          -5.02801500e-03, -6.59909964e-01,  1.31132337e-03,\n",
       "          -4.36734051e-01,  5.19469131e-06,  5.40188313e-01,\n",
       "           8.20766628e-01,  4.82120877e-03, -5.76093554e-01,\n",
       "          -6.92079216e-03, -3.04200836e-02, -1.50304837e-02,\n",
       "          -2.61034686e-02]], dtype=float32)>,\n",
       "  <tf.Tensor: id=1289, shape=(1, 256), dtype=float32, numpy=\n",
       "  array([[-4.07443702e-01, -9.17330563e-01, -1.22033501e+00,\n",
       "          -1.31508422e+00,  3.00655991e-01,  3.98103654e-01,\n",
       "          -9.16431397e-02, -7.04184473e-01, -1.03955591e+00,\n",
       "          -4.89993930e-01,  9.76561248e-01,  9.20456555e-03,\n",
       "           7.96496170e-04,  8.35935354e-01,  6.03055172e-02,\n",
       "           1.07483165e-02,  9.13967907e-01, -1.17537510e+00,\n",
       "          -2.07526505e-01, -6.58401474e-02, -4.52458598e-02,\n",
       "           1.06503487e+00, -8.88487160e-01,  4.88907516e-01,\n",
       "           7.90335536e-01,  8.00227225e-01,  4.03041765e-03,\n",
       "          -1.07065654e+00, -9.79137003e-01, -1.17923832e+00,\n",
       "           9.47588921e-01,  1.95245409e+00, -5.03901159e-04,\n",
       "           9.74441707e-01,  7.86270201e-01, -9.33402538e-01,\n",
       "          -9.85107064e-01,  4.62406874e-03, -1.32934202e-03,\n",
       "          -2.77346045e-01,  1.80594480e+00,  1.81814656e-01,\n",
       "           1.69293308e+00, -8.14144015e-01,  9.40549016e-01,\n",
       "          -1.85290623e+00,  4.18247373e-06,  7.41438508e-01,\n",
       "          -8.91466439e-03,  5.37303269e-01, -2.02959642e-01,\n",
       "          -4.72445637e-01,  5.57905734e-01,  1.12596691e-01,\n",
       "          -3.84786981e-05, -1.92886423e-02,  1.82735479e+00,\n",
       "           1.95946002e+00,  1.65257239e+00,  6.42129779e-02,\n",
       "           2.99272202e-02, -1.03484909e-03, -1.22842705e+00,\n",
       "           2.19788790e-01,  1.02601683e+00,  2.30503649e-01,\n",
       "           9.94045436e-01,  8.67133364e-02,  1.37846261e-01,\n",
       "          -1.63060869e-03,  1.42651409e-01,  1.95112184e-01,\n",
       "          -8.40351939e-01,  1.49617243e+00,  4.74549949e-01,\n",
       "           3.05287977e-05,  5.41439243e-02,  1.14827171e-01,\n",
       "           1.00377107e+00,  1.38912821e+00,  7.58991063e-01,\n",
       "          -1.01423240e+00,  4.83600616e-01,  5.39405107e-01,\n",
       "          -1.06180882e+00,  3.61213541e+00, -1.21978410e-02,\n",
       "           9.58330631e-02, -9.81262982e-01,  2.95457780e-01,\n",
       "           1.90495048e-05, -1.06470299e+00,  9.90821242e-01,\n",
       "           1.24295056e-01,  2.96444178e-01, -1.53393745e-01,\n",
       "          -1.12627137e+00, -1.78819656e+00, -1.27224554e-03,\n",
       "           9.34976161e-01,  3.86254080e-02, -7.07472265e-02,\n",
       "           6.73330843e-01,  2.02054949e-03,  1.35937512e+00,\n",
       "          -1.01136804e+00,  1.73564166e-01,  7.02589571e-01,\n",
       "           3.98708045e-01, -8.73218894e-01,  1.91139840e-02,\n",
       "           4.62568194e-01,  4.97125119e-01, -9.95268822e-01,\n",
       "           8.43906701e-01,  9.83217359e-01, -2.58249700e-01,\n",
       "           1.99274331e-01, -8.59974921e-01,  1.82059363e-01,\n",
       "           9.52122808e-02,  1.07220364e+00, -2.97859963e-03,\n",
       "           8.84686410e-01, -1.29701421e-02, -5.00637650e-01,\n",
       "          -7.26046145e-01, -3.32030794e-03,  4.94498700e-01,\n",
       "           3.69024009e-01,  4.49541330e-01, -1.20218098e+00,\n",
       "           2.77591050e-01,  7.63658106e-01,  3.90394703e-02,\n",
       "           6.98427618e-01,  9.82475698e-01,  2.33416721e-01,\n",
       "          -7.32274592e-01,  6.71849772e-03,  1.39047671e-07,\n",
       "          -1.15045875e-01,  9.49536800e-01,  1.09875548e+00,\n",
       "          -5.17587550e-03,  1.65256846e-03,  3.42220446e-04,\n",
       "           9.47065949e-02,  9.46978688e-01, -1.08441047e-01,\n",
       "           4.09186855e-02,  9.23475623e-01, -2.62618512e-01,\n",
       "           1.00956202e+00,  8.93962204e-01,  6.28043860e-02,\n",
       "          -2.19381345e-03, -1.00002754e+00, -8.10959101e-01,\n",
       "           5.78913689e-01, -9.66283008e-02, -5.36946021e-02,\n",
       "           2.84767479e-01, -9.92894173e-01, -1.18874443e+00,\n",
       "           2.42766994e-03,  1.68977344e+00,  6.56318665e-01,\n",
       "           2.01233792e+00, -8.83970022e-01, -9.98593509e-01,\n",
       "           1.29560560e-01,  1.52331495e+00,  7.72797406e-01,\n",
       "          -1.31970417e+00,  5.32044590e-01, -7.95083418e-02,\n",
       "          -9.31803584e-01,  1.79087985e+00,  7.09144259e-03,\n",
       "           1.23741722e+00, -9.92621124e-01, -1.15382969e-02,\n",
       "           2.86018639e-03,  6.36996090e-01,  4.30928171e-03,\n",
       "           9.63533700e-01, -3.41229111e-01,  1.62998665e-04,\n",
       "           1.40843436e-01, -1.02825761e+00,  1.02899313e-01,\n",
       "          -7.32636228e-02,  7.66460896e-01,  1.03665614e+00,\n",
       "          -9.92288113e-01, -1.17136979e+00,  6.45418346e-01,\n",
       "           1.15481949e+00,  2.43328601e-01, -3.95439798e-03,\n",
       "           2.24736825e-01, -9.94021535e-01, -6.62463680e-02,\n",
       "          -8.50223541e-01,  5.42457283e-01,  4.93266270e-04,\n",
       "          -7.85415545e-02, -8.47968161e-01, -1.84124634e-02,\n",
       "          -4.89180237e-01, -7.84389079e-01, -9.53651607e-01,\n",
       "           1.41849846e-01,  1.00037813e+00, -2.12526813e-01,\n",
       "          -6.49089098e-01,  1.74080968e+00,  9.66833770e-01,\n",
       "           1.17811803e-02, -4.25674319e-01,  6.60106003e-01,\n",
       "          -1.15298760e+00,  1.60668087e+00,  4.86430898e-03,\n",
       "           2.59738952e-01,  1.00143623e+00,  7.27115124e-02,\n",
       "           5.70577145e-01,  1.43431544e-01,  7.13637292e-01,\n",
       "           1.52097130e+00,  7.30715454e-01, -6.43182874e-01,\n",
       "          -9.59699899e-02, -9.92435575e-01, -1.02769993e-02,\n",
       "          -3.64699304e-01,  1.11283493e+00, -4.79218113e-04,\n",
       "           7.59947300e-01,  2.60014713e-01,  1.01796687e-02,\n",
       "          -5.46395546e-03, -7.93025255e-01,  4.40720290e-01,\n",
       "          -4.68734086e-01,  9.27838758e-02,  1.53234589e+00,\n",
       "           1.16480100e+00,  5.75746477e-01, -1.25237477e+00,\n",
       "          -2.98839137e-02, -3.04498002e-02, -1.50387110e-02,\n",
       "          -2.67524272e-01]], dtype=float32)>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = init_lstm_states(x.shape[0],num_hiddens)\n",
    "lstm(inputs,state,init_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_lstm = layers.LSTM(num_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1437, shape=(5, 1027), dtype=float32, numpy=\n",
       "array([[-0.00398049,  0.00267648, -0.00488786, ..., -0.00096839,\n",
       "         0.00080001,  0.00018608],\n",
       "       [ 0.00772672,  0.00621579, -0.00172489, ...,  0.0075411 ,\n",
       "        -0.00592683, -0.00439078],\n",
       "       [-0.00638593, -0.00090984,  0.00036399, ...,  0.00024921,\n",
       "         0.00673251,  0.00221328],\n",
       "       [-0.00393665, -0.00730946, -0.00665093, ..., -0.00705277,\n",
       "         0.00806974,  0.00484846],\n",
       "       [-0.00638531, -0.00075025, -0.00379624, ..., -0.00266368,\n",
       "         0.00155018, -0.00622312]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2.0",
   "language": "python",
   "name": "tensorflow2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
